

import pandas as pd
import re


rule decompress_assemblies:
    input:
        'assembly_gz/{sample}.fna.gz'
    output:
        temp('assembly_gz/{sample}.fna')
    shell:
        "zcat {input[0]} > {output[0]}"


rule print_primers_to_files :
    output:
        "InSilico/PCR/Primers.fasta"
    params:
        forward = config["forward_primer"],
        reverse = config["reverse_primer"]
    shell:
        '''
        printf \
        ">primer|F \n{params[0]} \n>primer|R \n{params[1]}" >> {output}
        '''


rule Extract_V3V4 :
    conda :
        "../../envs/simulate_PCR.yml"
    input :
        "InSilico/PCR/Primers.fasta",
        "assembly_gz/{sample}.fna"
    output :
        "InSilico/PCR/{sample}/Primers.fasta.pair.{sample}.fna.amplicons.fasta",
    params:
        min_length = config["merged_min_length"],
        max_length = config["merged_max_length"],
        mismatch = config["mismatch"],
        threeprime = config["threeprime"]
    log :
        logging_folder + "InSilico/PCR/{sample}/Primers.fasta.pair.{sample}.fna.amplicons.log",
    threads :
        1
    shell :
        '''
        cp {input[1]} $(dirname {output[0]}) && \
        cd $(dirname {output[0]}) && \
        simulate_PCR \
            -primers ../../../{input[0]} \
            -db $(basename {input[1]}) \
            -minlen {params.min_length} \
            -maxlen {params.max_length} \
            -mm {params.mismatch} \
            -3prime {params.threeprime} \
            -mux 0 \
            -num_threads {threads} \
            -max_target_seqs 1000000000 \
            -word_size 4 \
            -evalue 100000000 \
            -genes 1 \
            -extract_amp 1 \
            >> ../../../{log}
            
         '''



## Remove primers from sequences

rule cutadapt_trim_for_In_silico:
    conda:
        "../../envs/cutadapt.yml"
    input:
        raw_reads = "InSilico/PCR/{sample}/Primers.fasta.pair.{sample}.fna.amplicons.fasta",
    output:
        trimmed_reads = "InSilico/1a_trimmed_primers/{sample}_trimmed.fasta",
    log:
        logging_folder + "InSilico/1a_trimmed_primers/{sample}_trimmed.txt"
    params:
        forward_primer = config["forward_primer"],
        reverse_primer = config["reverse_primer"]
    threads:
        1
    shell:
        '''
        cutadapt \
        --cores {threads} \
        --error-rate 0.1 \
        --times 1 \
        --overlap 3 \
        -o {output[trimmed_reads]} \
        -b '{params[forward_primer]}' \
        -b '{params[reverse_primer]}' \
        --match-read-wildcards \
        {input[raw_reads]} >> {log}
        '''




def list_amplicons(wildcards):
    checkpoint_output = checkpoints.combine_assembly_tables.get(**wildcards).output[0]
    table=pd.read_csv(checkpoint_output,delimiter='\t')
    acc=list(table['AssemblyNames'])
    expd=expand("InSilico/1a_trimmed_primers/{sample}_trimmed.fasta",sample=acc)
    return expd

#primer enlever


### Combine all extracted sequences in one big fasta
rule Insilico_merge_all_in_one_fasta:
    input:
        list_amplicons
    output:
        "InSilico/1c_derep/merged_all.fasta"
    shell:
        '''
        cat {input} >> {output}
        '''


### Again, dereplicate all identical sequences after merging. Sequences must at least be twice in dataset to be kept.
rule InSilico_derepicate_all:
    conda:
        "../../envs/QIIME1.yml"
    input:
        "InSilico/1c_derep/merged_all.fasta"
    output:
        "InSilico/2_denoised/dna-sequences.fasta"
    log:
         logging_folder + "InSilico/1c_all_merged_sequences/dereplicate_all.txt"
    shell:
        '''
        vsearch --derep_fulllength {input} \
                --minuniquesize 2 \
                --output {output} \
                2> {log}
        '''



### Count the number of occurences of the representative sequences in the samples.
rule InSilico_count_occurences :
    conda:
        "../../envs/QIIME1.yml"
    input:
        samples = "InSilico/1a_trimmed_primers/{sample}_trimmed.fasta",
        rep_seq = "InSilico/2_denoised/dna-sequences.fasta"
    output:
        "InSilico/2_denoised/countOTUs/{sample}_count_table.txt",
    log:
         logging_folder + "InSilico/2_denoised/countOTUs/{sample}_count_table.txt"
    shell:
        '''
        vsearch --usearch_global {input[samples]} \
        -otutabout {output} \
        -id 1 \
        -strand plus \
        --db {input[rep_seq]} \
        2> {log}
        '''


def list_samples_counts(wildcards):
    checkpoint_output = checkpoints.combine_assembly_tables.get(**wildcards).output[0]
    table=pd.read_csv(checkpoint_output,delimiter='\t')
    acc=list(table['AssemblyNames'])
    expd=expand("InSilico/2_denoised/countOTUs/{sample}_count_table.txt",sample=acc)
    return expd


### Format count table from InSilico
rule create_InSilico_count_table :
    conda:
        "../../envs/r_visualization.yml"
    input:
        count_table_samples = list_samples_counts
    output:
        count_table = "InSilico/2_denoised/count_table.txt"
    log:
        logging_folder +  "InSilico/2_denoised/count_table.txt"
    script:
        "scripts/create_count_table_from_insilico.R"



### Create a table to compare tax assignment
rule In_silico_tax_compare:
    conda:
        "../../envs/physeq.yml"
    input:
        count_table = "InSilico/2_denoised/count_table.txt",
        Metadata_table = "table_combined.tsv",
        taxonomy_table = "InSilico/3_classified/{classifier}_{tax_DB}/dna-sequences_tax_assignments.txt",
    output:
        output_table = "InSilico/3_classified/{classifier}_{tax_DB}/InSilico_compare_tax.tsv"
    params:
        viz_replace_empty_tax = config["viz_replace_empty_tax"]
    log:
        logging_folder + "InSilico/3_classified/{classifier}_{tax_DB}/InSilico_compare_tax.log"
    script:
        "scripts/In_silico_tax_comparison.R"










